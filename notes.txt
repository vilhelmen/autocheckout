gitpython = no. It's a not-so-great wrapper that doesn't cover all my needs

Now everything is going to be more centralized.
There will be an initialization step involved.
But that leads to the question, do we offload import to classroom tools, or just do it ourselves?

... API access to the github import tool is under development and I'm not smart enough to write the API calls manually
... Same with repo locking

Octokit has all the features needed? But it's ruby/objective-c/.net, and I'm already having a hard enough time with python

Classroom's link setup is pretty nice. Although I suppose it could be done with a google form or something to collect usernames

https://github.com/sigmavirus24/github3.py for general management, scraping repos, etc.

consider
https://github.com/kennethreitz/requests
https://github.com/sigmavirus24/uritemplate
for commands for import & repo locking but maybe I'll just wait for now because ugh

Version ineedthisworking:

INIT:
	investigates path, making needed things
		repo dir
		git repo
		folder
			logs
			# datafile
				# token - string
				# workdir - string (not set yet, name of workspaces directory)
				# remote_enabled - bool, says if we should try to push all work
				# version - int(?), version number, because oh man will this change a lot
	Start logging
	# Authenticate
	# Create token
	# Offer to create key and add to account
	#		spit out ssh config blurb
	#		(name github.com, username git, key, identityonly, identityfile, etc)
	# Offer to create repo and hook into account
	terminate log
	add
	commit
	optionally push

REGISTER:
	validate # and load settings
	start logging, general and status
	add repos specified by file/stdin to workdir, logging success to status
	terminate logs
	add
	commit
	optionally push

CHECKOUT:
	validate and, PULL # THEN LOAD SETTINGS
	start logging, general and status
	recursive submodule fetch/merge/whatever
	submodule foreach (manual foreach?) of previous script(?), logging status
	(It may be better in the long run to manually do the updating and checking out)
	(This way, individual repos can be flagged as having errors, or whatnot)
	(Using foreach requires I parse my own output)
	(have git dump all submodule locations, run manually?)














LATER:

INIT:
	Make a new repo, unless dir/git repo already exists
	Check for current install (autocheckout dir exists), halt if it exists
	Make directory tree:
		autocheckout
			logs
				init.log (start log file, so when it's added, so it the direcotries, git doesn't like empty folders)

	Authenticate with git, get a token. Start building datastructure (map) for use with pickle
		track:
			token
			workspace dir (set by registration, just make empty)
			users (map of user_id and ids) (links github name to class id)

	write out data to autocheckout dir
	close logs
	Add, Commit, optionally create remote via api and push (this may fail if org/user doesn't have private repos)

REGISTER:
	This is two step at the moment :/